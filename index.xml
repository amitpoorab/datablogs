<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Amit Sharma — Data Engineering Blog</title>
    <link>https://example.com/</link>
    <description>Recent content on Amit Sharma — Data Engineering Blog</description>
    <generator>Hugo -- 0.152.2</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 10 Nov 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://example.com/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>How We Reduced Data Ingestion Time by 70% on a data Platform</title>
      <link>https://example.com/posts/how-we-reduced-data-ingestion-time/</link>
      <pubDate>Mon, 10 Nov 2025 00:00:00 +0000</pubDate>
      <guid>https://example.com/posts/how-we-reduced-data-ingestion-time/</guid>
      <description>&lt;h2 id=&#34;lessons-from-building-high-throughput-maintainable-data-lakes&#34;&gt;&lt;em&gt;Lessons from building high-throughput, maintainable data lakes&lt;/em&gt;&lt;/h2&gt;
&lt;h2 id=&#34;tldr&#34;&gt;TL;DR&lt;/h2&gt;
&lt;p&gt;As data platforms scale, small files on S3 quietly become one of the biggest performance bottlenecks. They slow down ingestion, inflate metadata operations, and make queries painfully sluggish.&lt;/p&gt;
&lt;p&gt;To address this, I explored using Apache Iceberg — not for its ACID guarantees, but for its metadata pruning, hidden partitioning, and compaction capabilities.
The result: ingestion times dropped by roughly 70%, and query planning improved dramatically, even on a large multi-petabyte test environment.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
